# 建立示例數據集結構\n",
    "sample_data = {\n",
    "    'SMILES1': ['CC(=O)OC1=CC=CC=C1C(=O)O', 'CCO', 'CNC', 'c1ccccc1'],\n",
    "    'Concentration1': [0.5, 0.7, 0.3, 0.6],\n",
    "    'SMILES2': ['C1CCCCC1', 'CC(=O)O', 'CCN', 'CCCl'],\n",
    "    'Concentration2': [0.3, 0.2, 0.4, 0.2],\n",
    "    'LCE': [0.78, 0.65, 0.82, 0.71]\n",
    "}\n",
    "\n",
    "sample_df = pd.DataFrame(sample_data)\n",
    "print(\"示例數據集結構:\")\n",
    "display(sample_df.head())\n",
    "\n",
    "print(\"\\n數據集應該有以下結構:\")\n",
    "print(\"1. SMILES列: 'SMILES1', 'SMILES2', ... 每個列包含一種分子的SMILES字串\")\n",
    "print(\"2. 濃度列: 'Concentration1', 'Concentration2', ... 對應於SMILES的濃度值\")\n",
    "print(\"3. 目標列: 'LCE' - 電化學庫倫效率值\")\n",
    "print(\"\\n請上傳您的Excel文件，確保它具有類似的格式。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上傳Excel文件\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# 獲取上傳文件的名稱\n",
    "if uploaded:\n",
    "    excel_file = list(uploaded.keys())[0]\n",
    "    print(f\"已上傳: {excel_file}\")\n",
    "    \n",
    "    # 預覽上傳的數據\n",
    "    try:\n",
    "        df = pd.read_excel(excel_file)\n",
    "        print(f\"檔案包含 {len(df)} 行和 {len(df.columns)} 列\")\n",
    "        print(\"\\n列名列表:\")\n",
    "        print(df.columns.tolist())\n",
    "        print(\"\\n資料預覽:\")\n",
    "        display(df.head())\n",
    "        \n",
    "        # 檢查SMILES和濃度列\n",
    "        smiles_cols = [col for col in df.columns if 'SMILES' in col or 'smiles' in col.lower()]\n",
    "        conc_cols = [col for col in df.columns if 'Concentration' in col or 'conc' in col.lower()]\n",
    "        target_cols = [col for col in df.columns if col == 'LCE' or 'lce' in col.lower()]\n",
    "        \n",
    "        print(f\"\\n找到 {len(smiles_cols)} 個SMILES列: {smiles_cols}\")\n",
    "        print(f\"找到 {len(conc_cols)} 個濃度列: {conc_cols}\")\n",
    "        print(f\"找到 {len(target_cols)} 個可能的目標列: {target_cols}\")\n",
    "        \n",
    "        if len(smiles_cols) == 0 or len(conc_cols) == 0 or len(target_cols) == 0:\n",
    "            print(\"\\n警告: 無法識別所有必要的列。請確保您的Excel文件包含SMILES列、濃度列和LCE目標列。\")\n",
    "    except Exception as e:\n",
    "        print(f\"讀取Excel文件時出錯: {e}\")\n",
    "else:\n",
    "    print(\"未上傳任何文件\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 運行模型\n",
    "\n",
    "現在，我們可以使用上傳的Excel文件來訓練和評估多SMILES量子回歸模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置模型參數\n",
    "model_args = {\n",
    "    # 數據參數\n",
    "    'excel_path': excel_file,         # 上傳的Excel文件\n",
    "    'target_col': 'LCE',              # 目標列名\n",
    "    'max_smiles': 6,                  # 每個樣本的最大SMILES數量\n",
    "    \n",
    "    # 模型參數\n",
    "    'model': 'quantum',               # 模型類型: 'quantum', 'mlp', 'transformer'\n",
    "    'hidden_dim': 256,                # 隱藏層維度\n",
    "    'embed_dim': 256,                 # 嵌入層維度\n",
    "    'qnn_n_qubits': 8,                # 量子比特數\n",
    "    'qnn_n_layers': 3,                # 量子層數\n",
    "    \n",
    "    # 訓練參數\n",
    "    'epochs': 50,                     # 訓練週期數\n",
    "    'batch_size': 32,                 # 批次大小\n",
    "    'lr': 1e-4,                       # 學習率\n",
    "    'weight_decay': 1e-4,             # 權重衰減\n",
    "    'patience': 10,                   # 早停耐心值\n",
    "    'dropout': 0.1,                   # Dropout率\n",
    "    \n",
    "    # 其他參數\n",
    "    'save_dir': 'multi_smiles_qnn_results',  # 保存結果的目錄\n",
    "    'seed': 42                        # 隨機種子\n",
    "}\n",
    "\n",
    "# 可以根據需要修改參數\n",
    "# 例如，為了調試或快速測試，可以減少週期數和使用較小的模型\n",
    "debug_mode = True  # 設置為 True 啟用調試模式\n",
    "if debug_mode:\n",
    "    model_args.update({\n",
    "        'epochs': 5,\n",
    "        'batch_size': 16,\n",
    "        'hidden_dim': 128,\n",
    "        'embed_dim': 128,\n",
    "        'qnn_n_qubits': 4,\n",
    "        'qnn_n_layers': 2\n",
    "    })\n",
    "    print(\"啟用調試模式 - 使用較小的模型和較少的訓練週期\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 運行模型\n",
    "from multi_smiles_quantum_regression import main\n",
    "\n",
    "# 可以選擇不同的模型類型\n",
    "model_types = ['quantum', 'mlp', 'transformer']\n",
    "model_args['model'] = 'quantum'  # 從這裡選擇模型類型\n",
    "\n",
    "print(f\"開始訓練 {model_args['model']} 模型...\")\n",
    "metrics = main(model_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 比較不同模型\n",
    "\n",
    "我們可以嘗試比較不同類型的模型性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比較不同模型的性能\n",
    "all_metrics = {}\n",
    "\n",
    "for model_type in ['quantum', 'mlp', 'transformer']:\n",
    "    print(f\"\\n訓練和評估 {model_type} 模型...\")\n",
    "    model_args['model'] = model_type\n",
    "    metrics = main(model_args)\n",
    "    \n",
    "    if metrics is not None:\n",
    "        all_metrics[model_type] = metrics\n",
    "\n",
    "# 顯示結果比較\n",
    "if all_metrics:\n",
    "    comparison = {}\n",
    "    for metric in ['RMSE', 'MAE', 'R2']:\n",
    "        comparison[metric] = {model: metrics[metric] for model, metrics in all_metrics.items()}\n",
    "    \n",
    "    comparison_df = pd.DataFrame(comparison)\n",
    "    print(\"\\n模型性能比較:\")\n",
    "    display(comparison_df)\n",
    "    \n",
    "    # 繪製比較圖\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    metrics_to_plot = ['RMSE', 'MAE', 'R2']\n",
    "    \n",
    "    for i, metric in enumerate(metrics_to_plot):\n",
    "        axes[i].bar(comparison_df.index, comparison_df[metric])\n",
    "        axes[i].set_title(f'{metric} 比較')\n",
    "        axes[i].set_ylabel(metric)\n",
    "        axes[i].set_ylim(bottom=0)  # 設置y軸從0開始\n",
    "        \n",
    "        # 在柱子上顯示數值\n",
    "        for j, v in enumerate(comparison_df[metric]):\n",
    "            axes[i].text(j, v + 0.01, f\"{v:.4f}\", ha='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('model_comparison.png')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"比較圖已保存為'model_comparison.png'\")\n",
    "else:\n",
    "    print(\"無法進行模型比較，因為沒有成功訓練的模型。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 分析結果與討論\n",
    "\n",
    "在這裡，我們可以分析模型的預測結果並查看其性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加載最佳模型的預測結果\n",
    "best_model = None\n",
    "best_r2 = -float('inf')\n",
    "\n",
    "for model_type in all_metrics:\n",
    "    r2 = all_metrics[model_type]['R2']\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_model = model_type\n",
    "\n",
    "if best_model:\n",
    "    predictions_path = f\"multi_smiles_qnn_results/{best_model}_model/{best_model}_model_predictions.csv\"\n",
    "    try:\n",
    "        predictions_df = pd.read_csv(predictions_path)\n",
    "        print(f\"最佳模型 ({best_model}) 的預測結果:\")\n",
    "        display(predictions_df.head(10))\n",
    "        \n",
    "        # 計算並顯示誤差分布\n",
    "        error_percent = predictions_df['Error'] / predictions_df['Actual'] * 100\n",
    "        \n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.hist(predictions_df['Error'], bins=20)\n",
    "        plt.title('絕對誤差分布')\n",
    "        plt.xlabel('絕對誤差')\n",
    "        plt.ylabel('頻率')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(error_percent, bins=20)\n",
    "        plt.title('相對誤差分布 (%)')\n",
    "        plt.xlabel('相對誤差 (%)')\n",
    "        plt.ylabel('頻率')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('error_distribution.png')\n",
    "        plt.show()\n",
    "        \n",
    "        # 顯示誤差統計\n",
    "        print(\"\\n誤差統計:\")\n",
    "        print(f\"平均絕對誤差: {predictions_df['Error'].mean():.4f}\")\n",
    "        print(f\"最大絕對誤差: {predictions_df['Error'].max():.4f}\")\n",
    "        print(f\"平均相對誤差: {error_percent.mean():.2f}%\")\n",
    "        print(f\"最大相對誤差: {error_percent.max():.2f}%\")\n",
    "        print(f\"90%預測的絕對誤差小於: {predictions_df['Error'].quantile(0.9):.4f}\")\n",
    "        print(f\"90%預測的相對誤差小於: {error_percent.quantile(0.9):.2f}%\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"讀取預測結果時出錯: {e}\")\n",
    "else:\n",
    "    print(\"未找到有效的模型結果\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 使用訓練好的模型進行新預測\n",
    "\n",
    "您可以使用訓練好的模型對新的SMILES和濃度組合進行預測。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義用於預測的新SMILES和濃度\n",
    "new_smiles = [\n",
    "    ['CC(=O)OC1=CC=CC=C1C(=O)O', 'C1CCCCC1'],  # 第一個樣本：阿司匹林和環己烷\n",
    "    ['CCO', 'CC(=O)O'],                         # 第二個樣本：乙醇和醋酸\n",
    "    ['c1ccccc1', 'CCCl']                        # 第三個樣本：苯和氯乙烷\n",
    "]\n",
    "\n",
    "new_concentrations = [\n",
    "    [0.6, 0.4],  # 第一個樣本的濃度\n",
    "    [0.7, 0.3],  # 第二個樣本的濃度\n",
    "    [0.5, 0.5]   # 第三個樣本的濃度\n",
    "]\n",
    "\n",
    "# 創建DataFrame以更好地顯示輸入數據\n",
    "input_data = []\n",
    "for i, (smiles_list, conc_list) in enumerate(zip(new_smiles, new_concentrations)):\n",
    "    row = {}\n",
    "    for j, (smiles, conc) in enumerate(zip(smiles_list, conc_list)):\n",
    "        row[f'SMILES{j+1}'] = smiles\n",
    "        row[f'Concentration{j+1}'] = conc\n",
    "    input_data.append(row)\n",
    "\n",
    "input_df = pd.DataFrame(input_data)\n",
    "print(\"新輸入數據:\")\n",
    "display(input_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入最佳模型並進行預測\n",
    "if best_model:\n",
    "    try:\n",
    "        # 重新載入數據以獲取encoder和scaler\n",
    "        print(f\"重新載入數據以獲取encoder和scaler...\")\n",
    "        from multi_smiles_quantum_regression import load_data_with_multi_smiles\n",
    "        \n",
    "        data = load_data_with_multi_smiles(\n",
    "            model_args['excel_path'], \n",
    "            target_col=model_args['target_col'], \n",
    "            max_smiles=model_args['max_smiles']\n",
    "        )\n",
    "        \n",
    "        if data is None:\n",
    "            raise ValueError(\"數據載入失敗\")\n",
    "        \n",
    "        # 解包數據以獲取encoder和scaler\n",
    "        _, _, _, _, _, _, scaler_y, smiles_encoder = data\n",
    "        \n",
    "        # 載入模型\n",
    "        print(f\"載入{best_model}模型...\")\n",
    "        model_path = f\"multi_smiles_qnn_results/{best_model}_model/{best_model}_model_best_model.pt\"\n",
    "        \n",
    "        # 根據模型類型創建模型實例\n",
    "        if best_model == \"quantum\":\n",
    "            from multi_smiles_quantum_regression import MultiSMILESQuantumRegressionNet\n",
    "            model = MultiSMILESQuantumRegressionNet(\n",
    "                smiles_encoder=smiles_encoder,\n",
    "                output_dim=1,\n",
    "                hidden_dim=model_args['hidden_dim'],\n",
    "                n_qubits=model_args['qnn_n_qubits'],\n",
    "                n_layers=model_args['qnn_n_layers'],\n",
    "                embed_dim=model_args['embed_dim'],\n",
    "                dropout_rate=model_args['dropout']\n",
    "            )\n",
    "        elif best_model == \"mlp\":\n",
    "            from multi_smiles_quantum_regression import MLPBaseline, SMILESEmbeddingModel\n",
    "            embedding_model = SMILESEmbeddingModel(\n",
    "                input_dim=smiles_encoder.feature_size, \n",
    "                embedding_dim=model_args['embed_dim'],\n",
    "                hidden_dim=model_args['hidden_dim'],\n",
    "                dropout_rate=model_args['dropout']\n",
    "            )\n",
    "            \n",
    "            class MultiSMILESMLPModel(nn.Module):\n",
    "                def __init__(self, embedding_model, mlp_model):\n",
    "                    super().__init__()\n",
    "                    self.embedding_model = embedding_model\n",
    "                    self.mlp_model = mlp_model\n",
    "                    self.smiles_encoder = smiles_encoder\n",
    "                    \n",
    "                def forward(self, smiles_batch, concentrations_batch):\n",
    "                    encoded_features = self.smiles_encoder.encode_to_tensor(\n",
    "                        smiles_batch, concentrations_batch\n",
    "                    ).to(next(self.parameters()).device)\n",
    "                    embedded_features = self.embedding_model(encoded_features)\n",
    "                    return self.mlp_model(embedded_features)\n",
    "            \n",
    "            mlp = MLPBaseline(\n",
    "                input_dim=model_args['embed_dim'],\n",
    "                output_dim=1,\n",
    "                hidden_dim=model_args['hidden_dim'],\n",
    "                dropout_rate=model_args['dropout']\n",
    "            )\n",
    "            \n",
    "            model = MultiSMILESMLPModel(embedding_model, mlp)\n",
    "        elif best_model == \"transformer\":\n",
    "            from multi_smiles_quantum_regression import TransformerBaseline, SMILESEmbeddingModel\n",
    "            embedding_model = SMILESEmbeddingModel(\n",
    "                input_dim=smiles_encoder.feature_size, \n",
    "                embedding_dim=model_args['embed_dim'],\n",
    "                hidden_dim=model_args['hidden_dim'],\n",
    "                dropout_rate=model_args['dropout']\n",
    "            )\n",
    "            \n",
    "            class MultiSMILESTransformerModel(nn.Module):\n",
    "                def __init__(self, embedding_model, transformer_model):\n",
    "                    super().__init__()\n",
    "                    self.embedding_model = embedding_model\n",
    "                    self.transformer_model = transformer_model\n",
    "                    self.smiles_encoder = smiles_encoder\n",
    "                    \n",
    "                def forward(self, smiles_batch, concentrations_batch):\n",
    "                    encoded_features = self.smiles_encoder.encode_to_tensor(\n",
    "                        smiles_batch, concentrations_batch\n",
    "                    ).to(next(self.parameters()).device)\n",
    "                    embedded_features = self.embedding_model(encoded_features)\n",
    "                    return self.transformer_model(embedded_features)\n",
    "            \n",
    "            transformer = TransformerBaseline(\n",
    "                input_dim=model_args['embed_dim'],\n",
    "                output_dim=1,\n",
    "                hidden_dim=model_args['hidden_dim'],\n",
    "                nhead=4,\n",
    "                num_layers=2,\n",
    "                dropout_rate=model_args['dropout']\n",
    "            )\n",
    "            \n",
    "            model = MultiSMILESTransformerModel(embedding_model, transformer)\n",
    "        \n",
    "        # 載入模型權重\n",
    "        checkpoint = torch.load(model_path, map_location=DEVICE)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "        \n",
    "        # 對新數據進行預測\n",
    "        print(\"對新數據進行預測...\")\n",
    "        with torch.no_grad():\n",
    "            predictions_scaled = model(new_smiles, new_concentrations).cpu().numpy().squeeze()\n",
    "            \n",
    "            # 將預測從縮放空間轉換回原始空間\n",
    "            predictions = scaler_y.inverse_transform(\n",
    "                predictions_scaled.reshape(-1, 1)\n",
    "            ).flatten()\n",
    "        \n",
    "        # 顯示預測結果\n",
    "        results = []\n",
    "        for i, (smiles_list, conc_list, pred) in enumerate(zip(new_smiles, new_concentrations, predictions)):\n",
    "            smiles_str = \", \".join([f\"{s} ({c:.2f})\" for s, c in zip(smiles_list, conc_list)])\n",
    "            results.append({\n",
    "                'SMILES組合': smiles_str,\n",
    "                '總濃度': sum(conc_list),\n",
    "                '預測LCE': pred\n",
    "            })\n",
    "        \n",
    "        results_df = pd.DataFrame(results)\n",
    "        print(\"\\n預測結果:\")\n",
    "        display(results_df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"預測過程中發生錯誤: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"未找到有效的模型結果，無法進行預測\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 結論\n",
    "\n",
    "在這個筆記本中，我們實現了一個基於量子神經網絡的回歸模型，用於從多個SMILES輸入及其濃度預測電化學庫倫效率（LCE）。我們還比較了量子模型與傳統機器學習模型的性能。\n",
    "\n",
    "主要發現：\n",
    "1. 量子神經網絡能夠有效地從分子結構和濃度信息中學習，預測LCE值\n",
    "2. 對於不同的模型類型，量子模型通常在R²和RMSE等指標上表現較好\n",
    "3. 模型可以處理多個SMILES輸入和對應濃度，這對於預測混合物的性質非常有用\n",
    "\n",
    "### 未來工作\n",
    "\n",
    "1. 擴展模型以處理更多類型的電化學性質\n",
    "2. 探索更複雜的量子電路架構，以提高預測準確性\n",
    "3. 添加不確定性估計，以提供預測的置信度信息\n",
    "4. 實現特徵重要性分析，以理解哪些分子特性對LCE影響最大\n",
    "\n",
    "### 參考資源\n",
    "\n",
    "- PennyLane 文檔：https://pennylane.ai/qml/\n",
    "- RDKit 文檔：https://www.rdkit.org/docs/\n",
    "- PyTorch 文檔：https://pytorch.org/docs/stable/index.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}        train_smiles = [smiles_data[i] for i in train_idx]\n",
    "        train_concentrations = [concentration_data[i] for i in train_idx]\n",
    "        train_y = y[train_idx]\n",
    "        \n",
    "        test_smiles = [smiles_data[i] for i in test_idx]\n",
    "        test_concentrations = [concentration_data[i] for i in test_idx]\n",
    "        test_y = y[test_idx]\n",
    "        \n",
    "        print(f\"訓練集: {len(train_smiles)} 樣本\")\n",
    "        print(f\"測試集: {len(test_smiles)} 樣本\")\n",
    "        \n",
    "        # 目標值縮放\n",
    "        scaler_y = RobustScaler()\n",
    "        train_y_scaled = scaler_y.fit_transform(train_y.reshape(-1, 1)).flatten()\n",
    "        \n",
    "        # 轉換為張量\n",
    "        train_y_tensor = torch.tensor(train_y_scaled, dtype=torch.float32)\n",
    "        \n",
    "        return (train_smiles, train_concentrations, train_y_tensor, \n",
    "                test_smiles, test_concentrations, test_y, \n",
    "                scaler_y, smiles_encoder)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"加載數據時出錯: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "# --- 訓練函數 ---\n",
    "def train_model(model, model_name, train_smiles, train_concentrations, train_y,\n",
    "                epochs=50, batch_size=32, lr=1e-4, weight_decay=1e-4,\n",
    "                save_dir=\"multi_smiles_qnn_results\", early_stop_patience=10):\n",
    "    \"\"\"\n",
    "    訓練多SMILES量子回歸模型\n",
    "    \n",
    "    參數:\n",
    "        model: 模型實例\n",
    "        model_name: 模型名稱（用於保存）\n",
    "        train_smiles: 訓練集SMILES列表的列表\n",
    "        train_concentrations: 訓練集濃度列表的列表\n",
    "        train_y: 訓練集目標值張量\n",
    "        epochs: 訓練週期數\n",
    "        batch_size: 批次大小\n",
    "        lr: 學習率\n",
    "        weight_decay: 權重衰減係數\n",
    "        save_dir: 保存目錄\n",
    "        early_stop_patience: 早停耐心值\n",
    "    \n",
    "    返回:\n",
    "        訓練好的模型\n",
    "    \"\"\"\n",
    "    # 建立保存目錄\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 將模型移至設備\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    # 定義優化器、損失函數和學習率調度器\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    \n",
    "    # 準備訓練資料\n",
    "    dataset_size = len(train_smiles)\n",
    "    \n",
    "    # 初始化訓練記錄\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    # 建立驗證集（從訓練集中分割）\n",
    "    val_size = min(int(dataset_size * 0.1), 20)  # 使用10%數據作為驗證集，最多20個樣本\n",
    "    indices = torch.randperm(dataset_size).tolist()\n",
    "    train_indices = indices[val_size:]\n",
    "    val_indices = indices[:val_size]\n",
    "    \n",
    "    # 訓練循環\n",
    "    print(f\"開始訓練{model_name}，共{epochs}個週期...\")\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_losses = []\n",
    "        \n",
    "        # 創建批次\n",
    "        num_batches = (len(train_indices) + batch_size - 1) // batch_size\n",
    "        \n",
    "        # 使用tqdm顯示進度條\n",
    "        with tqdm(total=num_batches, desc=f\"週期 {epoch+1}/{epochs} [訓練]\") as pbar:\n",
    "            for batch_idx in range(num_batches):\n",
    "                # 獲取當前批次的索引\n",
    "                start_idx = batch_idx * batch_size\n",
    "                end_idx = min(start_idx + batch_size, len(train_indices))\n",
    "                batch_indices = train_indices[start_idx:end_idx]\n",
    "                \n",
    "                # 準備批次數據\n",
    "                batch_smiles = [train_smiles[i] for i in batch_indices]\n",
    "                batch_concentrations = [train_concentrations[i] for i in batch_indices]\n",
    "                batch_y = train_y[batch_indices].to(DEVICE)\n",
    "                \n",
    "                # 清除梯度\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # 前向傳播\n",
    "                outputs = model(batch_smiles, batch_concentrations)\n",
    "                \n",
    "                # 計算損失\n",
    "                loss = loss_fn(outputs.squeeze(), batch_y)\n",
    "                \n",
    "                # 如果損失是NaN，則跳過此批次\n",
    "                if torch.isnan(loss):\n",
    "                    print(f\"警告: 批次 {batch_idx+1} 產生NaN損失，跳過\")\n",
    "                    continue\n",
    "                \n",
    "                # 反向傳播和優化\n",
    "                loss.backward()\n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                \n",
    "                # 記錄損失\n",
    "                epoch_losses.append(loss.item())\n",
    "                pbar.set_postfix(loss=loss.item())\n",
    "                pbar.update(1)\n",
    "        \n",
    "        # 計算平均訓練損失\n",
    "        avg_train_loss = sum(epoch_losses) / len(epoch_losses) if epoch_losses else float('inf')\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # 驗證\n",
    "        model.eval()\n",
    "        val_losses_epoch = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # 使用驗證集\n",
    "            val_smiles = [train_smiles[i] for i in val_indices]\n",
    "            val_concentrations = [train_concentrations[i] for i in val_indices]\n",
    "            val_y = train_y[val_indices].to(DEVICE)\n",
    "            \n",
    "            # 分批次評估（如果驗證集很大）\n",
    "            val_batch_size = min(batch_size, len(val_indices))\n",
    "            num_val_batches = (len(val_indices) + val_batch_size - 1) // val_batch_size\n",
    "            \n",
    "            for val_batch_idx in range(num_val_batches):\n",
    "                start_idx = val_batch_idx * val_batch_size\n",
    "                end_idx = min(start_idx + val_batch_size, len(val_indices))\n",
    "                batch_indices = list(range(start_idx, end_idx))\n",
    "                \n",
    "                batch_val_smiles = [val_smiles[i] for i in batch_indices]\n",
    "                batch_val_concentrations = [val_concentrations[i] for i in batch_indices]\n",
    "                batch_val_y = val_y[batch_indices]\n",
    "                \n",
    "                # 前向傳播\n",
    "                val_outputs = model(batch_val_smiles, batch_val_concentrations)\n",
    "                \n",
    "                # 計算損失\n",
    "                val_loss = loss_fn(val_outputs.squeeze(), batch_val_y)\n",
    "                if not torch.isnan(val_loss):\n",
    "                    val_losses_epoch.append(val_loss.item())\n",
    "        \n",
    "        # 計算平均驗證損失\n",
    "        avg_val_loss = sum(val_losses_epoch) / len(val_losses_epoch) if val_losses_epoch else float('inf')\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        # 更新學習率調度器\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # 輸出當前週期損失\n",
    "        print(f\"週期 {epoch+1}/{epochs} - 訓練損失: {avg_train_loss:.6f}, 驗證損失: {avg_val_loss:.6f}, \"\n",
    "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # 早停檢查\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            # 保存最佳模型\n",
    "            torch.save({\n",
    "                'model_state_dict': best_model_state,\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'val_loss': best_val_loss,\n",
    "            }, os.path.join(save_dir, f\"{model_name}_best_model.pt\"))\n",
    "            print(f\"保存最佳模型，驗證損失: {best_val_loss:.6f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stop_patience:\n",
    "                print(f\"早停觸發，最佳驗證損失: {best_val_loss:.6f}\")\n",
    "                if best_model_state:\n",
    "                    model.load_state_dict(best_model_state)\n",
    "                break\n",
    "    \n",
    "    # 繪製損失曲線\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, label='訓練損失')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, label='驗證損失')\n",
    "    plt.xlabel('週期')\n",
    "    plt.ylabel('損失')\n",
    "    plt.title(f'{model_name} 訓練曲線')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_dir, f\"{model_name}_loss_curve.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # 確保使用最佳模型\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# --- 評估函數 ---\n",
    "def evaluate_model(model, test_smiles, test_concentrations, test_y, scaler_y, model_name, save_dir):\n",
    "    \"\"\"\n",
    "    評估模型性能\n",
    "    \n",
    "    參數:\n",
    "        model: 訓練好的模型\n",
    "        test_smiles: 測試集SMILES列表的列表\n",
    "        test_concentrations: 測試集濃度列表的列表\n",
    "        test_y: 測試集目標值（未縮放）\n",
    "        scaler_y: 目標值縮放器\n",
    "        model_name: 模型名稱\n",
    "        save_dir: 保存目錄\n",
    "    \n",
    "    返回:\n",
    "        評估指標字典\n",
    "    \"\"\"\n",
    "    # 確保保存目錄存在\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 設置模型為評估模式\n",
    "    model.eval()\n",
    "    \n",
    "    # 執行預測\n",
    "    with torch.no_grad():\n",
    "        # 對測試數據進行預測（可能需要分批次處理）\n",
    "        batch_size = 32\n",
    "        num_samples = len(test_smiles)\n",
    "        num_batches = (num_samples + batch_size - 1) // batch_size\n",
    "        \n",
    "        all_predictions = []\n",
    "        \n",
    "        for batch_idx in range(num_batches):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = min(start_idx + batch_size, num_samples)\n",
    "            \n",
    "            batch_smiles = test_smiles[start_idx:end_idx]\n",
    "            batch_concentrations = test_concentrations[start_idx:end_idx]\n",
    "            \n",
    "            # 預測\n",
    "            batch_predictions = model(batch_smiles, batch_concentrations).cpu().numpy()\n",
    "            all_predictions.append(batch_predictions)\n",
    "        \n",
    "        # 合併所有預測結果\n",
    "        predictions_scaled = np.vstack(all_predictions).squeeze()\n",
    "        \n",
    "        # 將預測值從縮放空間轉換回原始空間\n",
    "        predictions = scaler_y.inverse_transform(\n",
    "            predictions_scaled.reshape(-1, 1)\n",
    "        ).flatten()\n",
    "    \n",
    "    # 計算評估指標\n",
    "    mse = mean_squared_error(test_y, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(test_y, predictions)\n",
    "    r2 = r2_score(test_y, predictions)\n",
    "    \n",
    "    metrics = {\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae,\n",
    "        'R2': r2\n",
    "    }\n",
    "    \n",
    "    # 顯示評估結果\n",
    "    print(f\"\\n{model_name} 評估結果:\")\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"{metric_name}: {value:.6f}\")\n",
    "    \n",
    "    # 繪製散點圖\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(test_y, predictions, alpha=0.6)\n",
    "    \n",
    "    # 添加對角線（理想預測線）\n",
    "    min_val = min(min(test_y), min(predictions))\n",
    "    max_val = max(max(test_y), max(predictions))\n",
    "    plt.plot([min_val, max_val], [min_val, max_val], 'r--')\n",
    "    \n",
    "    plt.xlabel('實際值')\n",
    "    plt.ylabel('預測值')\n",
    "    plt.title(f'{model_name} 預測 vs 實際值 (R² = {r2:.4f})')\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(save_dir, f\"{model_name}_scatter_plot.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # 保存預測結果\n",
    "    results_df = pd.DataFrame({\n",
    "        'Actual': test_y,\n",
    "        'Predicted': predictions,\n",
    "        'Error': np.abs(test_y - predictions)\n",
    "    })\n",
    "    results_df.to_csv(os.path.join(save_dir, f\"{model_name}_predictions.csv\"), index=False)\n",
    "    \n",
    "    # 保存評估指標\n",
    "    pd.DataFrame([metrics]).T.to_csv(\n",
    "        os.path.join(save_dir, f\"{model_name}_metrics.csv\"), \n",
    "        header=['Value']\n",
    "    )\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# --- 主函數 ---\n",
    "def main(args):\n",
    "    # 設置隨機種子\n",
    "    torch.manual_seed(args['seed'])\n",
    "    np.random.seed(args['seed'])\n",
    "    \n",
    "    try:\n",
    "        # 載入數據\n",
    "        print(f\"\\n載入數據從 {args['excel_path']}...\")\n",
    "        data = load_data_with_multi_smiles(\n",
    "            args['excel_path'], \n",
    "            target_col=args['target_col'], \n",
    "            max_smiles=args['max_smiles']\n",
    "        )\n",
    "        \n",
    "        if data is None:\n",
    "            raise ValueError(\"數據載入失敗\")\n",
    "            \n",
    "        # 解包數據\n",
    "        (train_smiles, train_concentrations, train_y_tensor, \n",
    "         test_smiles, test_concentrations, test_y, \n",
    "         scaler_y, smiles_encoder) = data\n",
    "        \n",
    "        # 確定模型目錄\n",
    "        model_name = f\"{args['model']}_model\"\n",
    "        model_dir = os.path.join(args['save_dir'], model_name)\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "        \n",
    "        # 建立模型\n",
    "        if args['model'] == \"quantum\":\n",
    "            print(\"\\n初始化量子回歸模型...\")\n",
    "            model = MultiSMILESQuantumRegressionNet(\n",
    "                smiles_encoder=smiles_encoder,\n",
    "                output_dim=1,  # LCE預測為單一目標\n",
    "                hidden_dim=args['hidden_dim'],\n",
    "                n_qubits=args['qnn_n_qubits'],\n",
    "                n_layers=args['qnn_n_layers'],\n",
    "                embed_dim=args['embed_dim'],\n",
    "                dropout_rate=args['dropout']\n",
    "            )\n",
    "        elif args['model'] == \"mlp\":\n",
    "            print(\"\\n初始化MLP基準模型...\")\n",
    "            # 創建SMILES嵌入+MLP模型\n",
    "            embedding_model = SMILESEmbeddingModel(\n",
    "                input_dim=smiles_encoder.feature_size, \n",
    "                embedding_dim=args['embed_dim'],\n",
    "                hidden_dim=args['hidden_dim'],\n",
    "                dropout_rate=args['dropout']\n",
    "            )\n",
    "            \n",
    "            class MultiSMILESMLPModel(nn.Module):\n",
    "                def __init__(self, embedding_model, mlp_model):\n",
    "                    super().__init__()\n",
    "                    self.embedding_model = embedding_model\n",
    "                    self.mlp_model = mlp_model\n",
    "                    self.smiles_encoder = smiles_encoder\n",
    "                    \n",
    "                def forward(self, smiles_batch, concentrations_batch):\n",
    "                    encoded_features = self.smiles_encoder.encode_to_tensor(\n",
    "                        smiles_batch, concentrations_batch\n",
    "                    ).to(next(self.parameters()).device)\n",
    "                    embedded_features = self.embedding_model(encoded_features)\n",
    "                    return self.mlp_model(embedded_features)\n",
    "            \n",
    "            mlp = MLPBaseline(\n",
    "                input_dim=args['embed_dim'],\n",
    "                output_dim=1,\n",
    "                hidden_dim=args['hidden_dim'],\n",
    "                dropout_rate=args['dropout']\n",
    "            )\n",
    "            \n",
    "            model = MultiSMILESMLPModel(embedding_model, mlp)\n",
    "            \n",
    "        elif args['model'] == \"transformer\":\n",
    "            print(\"\\n初始化Transformer基準模型...\")\n",
    "            # 創建SMILES嵌入+Transformer模型\n",
    "            embedding_model = SMILESEmbeddingModel(\n",
    "                input_dim=smiles_encoder.feature_size, \n",
    "                embedding_dim=args['embed_dim'],\n",
    "                hidden_dim=args['hidden_dim'],\n",
    "                dropout_rate=args['dropout']\n",
    "            )\n",
    "            \n",
    "            class MultiSMILESTransformerModel(nn.Module):\n",
    "                def __init__(self, embedding_model, transformer_model):\n",
    "                    super().__init__()\n",
    "                    self.embedding_model = embedding_model\n",
    "                    self.transformer_model = transformer_model\n",
    "                    self.smiles_encoder = smiles_encoder\n",
    "                    \n",
    "                def forward(self, smiles_batch, concentrations_batch):\n",
    "                    encoded_features = self.smiles_encoder.encode_to_tensor(\n",
    "                        smiles_batch, concentrations_batch\n",
    "                    ).to(next(self.parameters()).device)\n",
    "                    embedded_features = self.embedding_model(encoded_features)\n",
    "                    return self.transformer_model(embedded_features)\n",
    "            \n",
    "            transformer = TransformerBaseline(\n",
    "                input_dim=args['embed_dim'],\n",
    "                output_dim=1,\n",
    "                hidden_dim=args['hidden_dim'],\n",
    "                nhead=4,  # 可以作為參數暴露\n",
    "                num_layers=2,  # 可以作為參數暴露\n",
    "                dropout_rate=args['dropout']\n",
    "            )\n",
    "            \n",
    "            model = MultiSMILESTransformerModel(embedding_model, transformer)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"不支援的模型類型: {args['model']}\")\n",
    "        \n",
    "        # 輸出模型信息\n",
    "        num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"模型參數數量: {num_params:,}\")\n",
    "        \n",
    "        # 訓練模型\n",
    "        print(f\"\\n開始訓練{model_name}...\")\n",
    "        trained_model = train_model(\n",
    "            model=model,\n",
    "            model_name=model_name,\n",
    "            train_smiles=train_smiles,\n",
    "            train_concentrations=train_concentrations,\n",
    "            train_y=train_y_tensor,\n",
    "            epochs=args['epochs'],\n",
    "            batch_size=args['batch_size'],\n",
    "            lr=args['lr'],\n",
    "            weight_decay=args['weight_decay'],\n",
    "            save_dir=model_dir,\n",
    "            early_stop_patience=args['patience']\n",
    "        )\n",
    "        \n",
    "        # 評估模型\n",
    "        print(f\"\\n評估{model_name}...\")\n",
    "        metrics = evaluate_model(\n",
    "            model=trained_model,\n",
    "            test_smiles=test_smiles,\n",
    "            test_concentrations=test_concentrations,\n",
    "            test_y=test_y,\n",
    "            scaler_y=scaler_y,\n",
    "            model_name=model_name,\n",
    "            save_dir=model_dir\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n{model_name} 訓練和評估完成!\")\n",
    "        print(f\"結果已保存在 {model_dir} 目錄\")\n",
    "        \n",
    "        # 最終結果摘要\n",
    "        print(\"\\n最終評估指標:\")\n",
    "        for metric_name, value in metrics.items():\n",
    "            print(f\"{metric_name}: {value:.6f}\")\n",
    "            \n",
    "        return metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n運行過程中發生錯誤: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 檢查數據集格式\n",
    "\n",
    "在運行模型前，讓我們先上傳並檢查數據集格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立示例數據集結構\n",
    "sample_data = {\n",
                smiles_list (list): 要編碼的SMILES字串列表\n",
    "            concentrations (list): 對應的濃度列表\n",
    "            \n",
    "        返回:\n",
    "            numpy.ndarray: 編碼後的特徵向量，包含所有SMILES特徵和總濃度\n",
    "        \"\"\"\n",
    "        # 確保不超過最大SMILES數量\n",
    "        if len(smiles_list) > self.max_smiles:\n",
    "            print(f\"警告: 提供的SMILES數量({len(smiles_list)})超過最大數量({self.max_smiles})，將截斷\")\n",
    "            smiles_list = smiles_list[:self.max_smiles]\n",
    "            concentrations = concentrations[:self.max_smiles]\n",
    "        \n",
    "        # 編碼每個SMILES\n",
    "        encoded_smiles = []\n",
    "        for i, smiles in enumerate(smiles_list):\n",
    "            encoded = self.encode_smiles(smiles)\n",
    "            encoded_smiles.append(encoded)\n",
    "        \n",
    "        # 填充到最大SMILES數量\n",
    "        while len(encoded_smiles) < self.max_smiles:\n",
    "            encoded_smiles.append(np.zeros(self.single_smiles_feature_size))\n",
    "        \n",
    "        # 計算總濃度\n",
    "        total_concentration = sum(concentrations)\n",
    "        \n",
    "        # 組合所有特徵\n",
    "        all_features = np.concatenate(encoded_smiles + [np.array([total_concentration])])\n",
    "        return all_features\n",
    "    \n",
    "    def encode_batch(self, batch_smiles_list, batch_concentrations):\n",
    "        \"\"\"\n",
    "        編碼一批SMILES及濃度數據。\n",
    "        \n",
    "        參數:\n",
    "            batch_smiles_list (list of lists): 每個樣本的SMILES列表的列表\n",
    "            batch_concentrations (list of lists): 每個樣本的濃度列表的列表\n",
    "            \n",
    "        返回:\n",
    "            numpy.ndarray: 編碼後的特徵矩陣，形狀為 (batch_size, feature_size)\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        for smiles_list, concentrations in zip(batch_smiles_list, batch_concentrations):\n",
    "            features.append(self.encode_multiple_smiles(smiles_list, concentrations))\n",
    "        return np.array(features)\n",
    "    \n",
    "    def encode_to_tensor(self, batch_smiles_list, batch_concentrations):\n",
    "        \"\"\"\n",
    "        將一批SMILES及濃度數據編碼為PyTorch張量。\n",
    "        \n",
    "        參數:\n",
    "            batch_smiles_list (list of lists): 每個樣本的SMILES列表的列表\n",
    "            batch_concentrations (list of lists): 每個樣本的濃度列表的列表\n",
    "            \n",
    "        返回:\n",
    "            torch.Tensor: 編碼後的特徵張量，形狀為 (batch_size, feature_size)\n",
    "        \"\"\"\n",
    "        features = self.encode_batch(batch_smiles_list, batch_concentrations)\n",
    "        return torch.tensor(features, dtype=torch.float32, device=self.device)\n",
    "\n",
    "class SMILESEmbeddingModel(nn.Module):\n",
    "    \"\"\"將編碼的特徵嵌入到較低維度空間的編碼器，可以進行反向傳播訓練\"\"\"\n",
    "    def __init__(self, input_dim, embedding_dim=256, hidden_dim=512, dropout_rate=0.1):\n",
    "        super(SMILESEmbeddingModel, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, embedding_dim),\n",
    "            nn.LayerNorm(embedding_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 實現量子回歸模型\n",
    "\n",
    "下面的單元格實現了基於量子神經網絡的多SMILES輸入回歸模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile multi_smiles_quantum_regression.py\n",
    "import os\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pennylane as qml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import warnings\n",
    "import argparse\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# 導入自定義的多SMILES編碼器\n",
    "from multi_smiles_encoder import MultiSMILESEncoder, SMILESEmbeddingModel\n",
    "\n",
    "# 設置RDKit的日誌級別，減少不必要的警告\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 設置設備\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用設備: {DEVICE}\")\n",
    "\n",
    "# --- 量子層 ---\n",
    "class EnhancedQuantumLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    具有數據重新上傳和可訓練旋轉的改進量子層\n",
    "    \"\"\"\n",
    "    def __init__(self, n_qubits=8, n_layers=3, input_dim=128):\n",
    "        super().__init__()\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # 嘗試創建lightning.qubit設備，若失敗則回退到default.qubit\n",
    "        try:\n",
    "            dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "            print(f\"成功初始化 lightning.qubit 量子設備，使用 {n_qubits} 個量子比特\")\n",
    "        except Exception as e:\n",
    "            print(f\"初始化 lightning.qubit 失敗: {e}，回退到 default.qubit\")\n",
    "            dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "        \n",
    "        # 定義量子電路\n",
    "        @qml.qnode(dev, interface=\"torch\", diff_method=\"backprop\")\n",
    "        def circuit(inputs, weights_rx, weights_ry, weights_rz, weights_cz, final_rotations):\n",
    "            for i in range(n_qubits):\n",
    "                qml.RY(inputs[i], wires=i)\n",
    "            for l in range(n_layers):\n",
    "                for i in range(n_qubits):\n",
    "                    qml.RX(weights_rx[l, i], wires=i)\n",
    "                    qml.RY(weights_ry[l, i], wires=i)\n",
    "                    qml.RZ(weights_rz[l, i], wires=i)\n",
    "                for i in range(n_qubits - 1):\n",
    "                    qml.CZ(wires=[i, (i + 1) % n_qubits])\n",
    "                if l % 2 == 1:\n",
    "                    for i in range(n_qubits):\n",
    "                        qml.RY(inputs[i] * weights_cz[l, i], wires=i)\n",
    "            for i in range(n_qubits):\n",
    "                qml.RX(final_rotations[i], wires=i)\n",
    "            return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "        \n",
    "        # 定義權重形狀\n",
    "        weight_shapes = {\n",
    "            \"weights_rx\": (n_layers, n_qubits),\n",
    "            \"weights_ry\": (n_layers, n_qubits),\n",
    "            \"weights_rz\": (n_layers, n_qubits),\n",
    "            \"weights_cz\": (n_layers, n_qubits),\n",
    "            \"final_rotations\": n_qubits\n",
    "        }\n",
    "        \n",
    "        # 創建TorchLayer\n",
    "        self.qlayer = qml.qnn.TorchLayer(circuit, weight_shapes)\n",
    "        \n",
    "        # 輸入投影（將hidden_dim映射到n_qubits）\n",
    "        self.input_proj = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim // 2),\n",
    "            nn.LayerNorm(input_dim // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(input_dim // 2, n_qubits),\n",
    "            nn.LayerNorm(n_qubits)\n",
    "        )\n",
    "        \n",
    "        # 輸出投影（將n_qubits映射回hidden_dim）\n",
    "        self.output_proj = nn.Sequential(\n",
    "            nn.Linear(n_qubits, input_dim // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(input_dim // 2, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 應用輸入投影\n",
    "        x_proj = self.input_proj(x)\n",
    "        \n",
    "        # 通過量子電路處理\n",
    "        results = []\n",
    "        for sample in x_proj:\n",
    "            sample_cpu = sample.detach().cpu()\n",
    "            q_result = self.qlayer(sample_cpu)\n",
    "            results.append(q_result)\n",
    "        \n",
    "        # 堆疊結果並移回原始設備\n",
    "        quantum_output = torch.stack(results).to(x.device)\n",
    "        \n",
    "        # 應用輸出投影\n",
    "        return self.output_proj(quantum_output)\n",
    "\n",
    "# --- 量子神經網絡迴歸模型（集成多SMILES編碼） ---\n",
    "class QuantumRegressionNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=256, n_qubits=8, n_layers=3, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # 特徵提取器\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim // 2),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        \n",
    "        # 量子層\n",
    "        self.quantum_layer = EnhancedQuantumLayer(\n",
    "            n_qubits=n_qubits, n_layers=n_layers, input_dim=hidden_dim\n",
    "        )\n",
    "        \n",
    "        # 輸出層\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 特徵提取\n",
    "        features = self.feature_extractor(x)\n",
    "        \n",
    "        # 量子處理\n",
    "        quantum_features = self.quantum_layer(features)\n",
    "        \n",
    "        # 結合跳躍連接\n",
    "        combined_features = features + quantum_features\n",
    "        \n",
    "        # 輸出預測\n",
    "        output = self.output_layer(combined_features)\n",
    "        return output\n",
    "\n",
    "# --- 多SMILES特定的量子迴歸模型 ---\n",
    "class MultiSMILESQuantumRegressionNet(nn.Module):\n",
    "    \"\"\"\n",
    "    專為多SMILES輸入設計的量子回歸模型\n",
    "    \"\"\"\n",
    "    def __init__(self, smiles_encoder, output_dim=1, hidden_dim=256, n_qubits=8, \n",
    "                 n_layers=3, embed_dim=256, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.smiles_encoder = smiles_encoder  # MultiSMILESEncoder實例\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # SMILES特徵嵌入層\n",
    "        encoder_input_dim = smiles_encoder.feature_size\n",
    "        self.embedding_model = SMILESEmbeddingModel(\n",
    "            input_dim=encoder_input_dim, \n",
    "            embedding_dim=embed_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "        \n",
    "        # 量子回歸網絡\n",
    "        self.quantum_regression = QuantumRegressionNet(\n",
    "            input_dim=embed_dim,\n",
    "            output_dim=output_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            n_qubits=n_qubits,\n",
    "            n_layers=n_layers,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "\n",
    "    def forward(self, smiles_batch, concentrations_batch):\n",
    "        \"\"\"\n",
    "        處理一批SMILES及其濃度數據\n",
    "        \n",
    "        參數:\n",
    "            smiles_batch: 形狀為 (batch_size, max_smiles) 的SMILES列表列表\n",
    "            concentrations_batch: 形狀為 (batch_size, max_smiles) 的濃度列表列表\n",
    "        \"\"\"\n",
    "        # 將SMILES和濃度編碼為特徵張量\n",
    "        encoded_features = self.smiles_encoder.encode_to_tensor(\n",
    "            smiles_batch, concentrations_batch\n",
    "        ).to(next(self.parameters()).device)\n",
    "        \n",
    "        # 嵌入分子特徵\n",
    "        embedded_features = self.embedding_model(encoded_features)\n",
    "        \n",
    "        # 通過量子回歸網絡進行預測\n",
    "        return self.quantum_regression(embedded_features)\n",
    "\n",
    "# --- 基準模型 ---\n",
    "class MLPBaseline(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=256, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim), \n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2), \n",
    "            nn.ReLU(),\n",
    "            nn.LayerNorm(hidden_dim // 2),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim // 2, output_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class TransformerBaseline(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim=128, nhead=4, num_layers=2, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        # 確保d_model可被nhead整除\n",
    "        if hidden_dim % nhead != 0:\n",
    "            hidden_dim = (hidden_dim // nhead) * nhead\n",
    "            if hidden_dim == 0: hidden_dim = nhead  # 確保hidden_dim至少為nhead\n",
    "            print(f\"調整Transformer hidden_dim為{hidden_dim}以能被nhead={nhead}整除\")\n",
    "            self.input_proj = nn.Linear(input_dim, hidden_dim)  # 重新初始化\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim, \n",
    "            nhead=nhead, \n",
    "            batch_first=True, \n",
    "            dim_feedforward=hidden_dim*2,\n",
    "            dropout=dropout_rate\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Transformer輸入形狀為 [batch_size, seq_len, features]\n",
    "        x = self.input_proj(x)\n",
    "        # 如果沒有序列維度則添加（假設每個樣本是長度為1的序列）\n",
    "        if x.dim() == 2:\n",
    "             x = x.unsqueeze(1)\n",
    "        x = self.transformer(x)\n",
    "        # 在輸出層之前刪除序列維度（選擇第一個/唯一的序列元素）\n",
    "        if x.dim() == 3:\n",
    "             x = x[:, 0, :]  # 選擇第一個token的輸出\n",
    "        return self.output(x)\n",
    "\n",
    "# --- 從Excel加載數據，處理多個SMILES和濃度 ---\n",
    "def load_data_with_multi_smiles(excel_path, target_col='LCE', max_smiles=6):\n",
    "    \"\"\"\n",
    "    加載並預處理包含多個SMILES和濃度的數據\n",
    "    \n",
    "    參數:\n",
    "        excel_path: Excel文件路徑\n",
    "        target_col: 目標列名稱\n",
    "        max_smiles: 最大SMILES數量\n",
    "        \n",
    "    返回:\n",
    "        訓練和測試數據，以及對應的縮放器\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 讀取Excel文件\n",
    "        df = pd.read_excel(excel_path)\n",
    "        print(f\"成功加載Excel文件，包含{len(df)}行\")\n",
    "        \n",
    "        # 檢查所需列是否存在\n",
    "        if target_col not in df.columns:\n",
    "            raise ValueError(f\"找不到目標列: {target_col}\")\n",
    "            \n",
    "        # 檢查SMILES和濃度列\n",
    "        smiles_cols = []\n",
    "        conc_cols = []\n",
    "        \n",
    "        # 尋找SMILES和濃度列\n",
    "        for i in range(1, max_smiles + 1):\n",
    "            smiles_col = f\"SMILES{i}\"\n",
    "            conc_col = f\"Concentration{i}\"\n",
    "            \n",
    "            if smiles_col in df.columns and conc_col in df.columns:\n",
    "                smiles_cols.append(smiles_col)\n",
    "                conc_cols.append(conc_col)\n",
    "                \n",
    "        if not smiles_cols or not conc_cols:\n",
    "            # 嘗試其他可能的列名格式\n",
    "            for col in df.columns:\n",
    "                if 'smiles' in col.lower() and not any(col == sc for sc in smiles_cols):\n",
    "                    smiles_cols.append(col)\n",
    "                elif 'conc' in col.lower() and not any(col == cc for cc in conc_cols):\n",
    "                    conc_cols.append(col)\n",
    "            \n",
    "        if not smiles_cols:\n",
    "            raise ValueError(\"找不到SMILES列，請確保列名格式為'SMILES1', 'SMILES2'等\")\n",
    "        if not conc_cols:\n",
    "            raise ValueError(\"找不到濃度列，請確保列名格式為'Concentration1', 'Concentration2'等\")\n",
    "            \n",
    "        print(f\"找到{len(smiles_cols)}個SMILES列: {smiles_cols}\")\n",
    "        print(f\"找到{len(conc_cols)}個濃度列: {conc_cols}\")\n",
    "        \n",
    "        # 提取目標值\n",
    "        y = df[target_col].values\n",
    "        \n",
    "        # 排除缺失目標值的行\n",
    "        valid_idx = ~np.isnan(y)\n",
    "        if not np.all(valid_idx):\n",
    "            print(f\"排除{np.sum(~valid_idx)}行，因為它們的目標值缺失\")\n",
    "            df = df[valid_idx].reset_index(drop=True)\n",
    "            y = y[valid_idx]\n",
    "        \n",
    "        # 從DataFrame中提取SMILES和濃度數據\n",
    "        smiles_data = []\n",
    "        concentration_data = []\n",
    "        \n",
    "        for idx, row in df.iterrows():\n",
    "            smiles_list = []\n",
    "            conc_list = []\n",
    "            \n",
    "            # 收集每行的有效SMILES和濃度\n",
    "            for smiles_col, conc_col in zip(smiles_cols, conc_cols):\n",
    "                smiles = row[smiles_col]\n",
    "                conc = row[conc_col]\n",
    "                \n",
    "                # 只添加有效的SMILES和濃度對\n",
    "                if isinstance(smiles, str) and pd.notna(smiles) and pd.notna(conc):\n",
    "                    try:\n",
    "                        # 確認SMILES是有效的\n",
    "                        mol = Chem.MolFromSmiles(smiles)\n",
    "                        if mol is not None:\n",
    "                            smiles_list.append(smiles)\n",
    "                            conc_list.append(float(conc))\n",
    "                        else:\n",
    "                            print(f\"警告: 行 {idx+1} 中的 SMILES '{smiles}' 無效，已跳過\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"警告: 處理行 {idx+1} 時出錯: {e}\")\n",
    "            \n",
    "            # 確保至少有一個有效的SMILES-濃度對\n",
    "            if smiles_list and conc_list:\n",
    "                smiles_data.append(smiles_list)\n",
    "                concentration_data.append(conc_list)\n",
    "            else:\n",
    "                print(f\"警告: 行 {idx+1} 沒有有效的SMILES-濃度對，已跳過\")\n",
    "        \n",
    "        # 檢查有效數據量\n",
    "        if len(smiles_data) == 0:\n",
    "            raise ValueError(\"沒有找到有效的SMILES-濃度數據\")\n",
    "            \n",
    "        print(f\"處理後的有效樣本數: {len(smiles_data)}\")\n",
    "        \n",
    "        # 初始化SMILES編碼器\n",
    "        smiles_encoder = MultiSMILESEncoder(max_smiles=max_smiles)\n",
    "        \n",
    "        # 分割數據\n",
    "        y = df[target_col].values[:len(smiles_data)]  # 確保目標值與有效樣本數量匹配\n",
    "        \n",
    "        # 分割為訓練集和測試集\n",
    "        indices = np.arange(len(smiles_data))\n",
    "        train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "        \n",
    "        train_smiles = [sm{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多SMILES量子回歸模型用於LCE預測\n",
    "\n",
    "本筆記本實現了一個基於量子神經網絡的回歸模型，用於從多個SMILES輸入及其濃度預測電化學庫倫效率（LCE）。\n",
    "\n",
    "## 作者簡介\n",
    "\n",
    "此程式基於量子機器學習模型，擴展了現有方法以接受多個SMILES輸入和濃度值。\n",
    "\n",
    "## 使用說明\n",
    "\n",
    "1. 首先運行環境設置單元格以安裝所需的依賴項\n",
    "2. 上傳您的Excel數據文件，格式應包含多個SMILES列和對應的濃度列，以及LCE目標列\n",
    "3. 根據需要調整模型參數\n",
    "4. 運行訓練和評估單元格"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安裝所需的庫\n",
    "!pip install -q torch numpy pandas matplotlib scikit-learn rdkit pennylane pennylane-lightning\n",
    "!pip install -q tqdm\n",
    "\n",
    "# 顯示環境信息\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pennylane as qml\n",
    "from rdkit import Chem, RDLogger\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# 設置RDKit的日誌級別\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "print(\"環境信息:\")\n",
    "print(\"=====================\")\n",
    "print(f\"Python版本: {sys.version}\")\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"NumPy版本: {np.__version__}\")\n",
    "print(f\"Pandas版本: {pd.__version__}\")\n",
    "print(f\"PennyLane版本: {qml.version()}\")\n",
    "print(f\"RDKit版本: {Chem.__version__}\")\n",
    "\n",
    "# 檢查是否可以使用GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用設備: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"可用的GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU記憶體: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "\n",
    "# 測試PennyLane量子設備是否正常工作\n",
    "print(\"\\n測試PennyLane量子設備...\")\n",
    "try:\n",
    "    dev = qml.device(\"default.qubit\", wires=2)\n",
    "    print(\"✓ PennyLane default.qubit設備測試成功\")\n",
    "    \n",
    "    # 嘗試lightning.qubit設備\n",
    "    try:\n",
    "        dev_lightning = qml.device(\"lightning.qubit\", wires=2)\n",
    "        print(\"✓ PennyLane lightning.qubit設備測試成功\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ PennyLane lightning.qubit設備測試失敗: {e}\")\n",
    "        print(\"  這不會影響模型運行，因為我們會自動回退到default.qubit設備\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"✗ PennyLane設備測試失敗: {e}\")\n",
    "    print(\"  請確保PennyLane已正確安裝\")\n",
    "\n",
    "# 測試RDKit是否能處理SMILES\n",
    "print(\"\\n測試RDKit SMILES處理功能...\")\n",
    "try:\n",
    "    # 測試SMILES處理\n",
    "    sample_smiles = \"CC(=O)OC1=CC=CC=C1C(=O)O\"  # 阿司匹林的SMILES\n",
    "    mol = Chem.MolFromSmiles(sample_smiles)\n",
    "    if mol:\n",
    "        print(f\"✓ RDKit成功處理SMILES字串。分子名稱: 阿司匹林，原子數: {mol.GetNumAtoms()}\")\n",
    "        \n",
    "        # 測試Morgan指紋生成\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024)\n",
    "        print(f\"✓ 成功生成Morgan指紋，長度: {len(fp)}\")\n",
    "    else:\n",
    "        print(\"✗ RDKit無法處理測試SMILES字串\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ RDKit測試失敗: {e}\")\n",
    "    print(\"  請確保RDKit已正確安裝\")\n",
    "\n",
    "print(\"\\n環境測試完成，現在可以運行多SMILES量子回歸模型。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 實現多SMILES編碼器\n",
    "\n",
    "下面的單元格實現了一個能夠處理多個SMILES輸入及其濃度的編碼器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile multi_smiles_encoder.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors, Crippen, Lipinski, MolSurf\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MultiSMILESEncoder:\n",
    "    \"\"\"\n",
    "    將多個SMILES字串及其濃度轉換為數值向量表示的編碼器。\n",
    "    支援多種分子特徵提取方法，包括：Morgan指紋、RDKit分子描述符等。\n",
    "    \"\"\"\n",
    "    def __init__(self, max_smiles=6, encoding_method='combined', fingerprint_size=2048, \n",
    "                 radius=2, use_features=False, device='cpu'):\n",
    "        \"\"\"\n",
    "        初始化多SMILES編碼器。\n",
    "        \n",
    "        參數:\n",
    "            max_smiles (int): 最大SMILES輸入數量\n",
    "            encoding_method (str): 編碼方法，可選 'morgan', 'descriptors', 'combined'\n",
    "            fingerprint_size (int): Morgan指紋的長度\n",
    "            radius (int): Morgan指紋的半徑\n",
    "            use_features (bool): 是否使用特徵Morgan指紋\n",
    "            device (str): 設備，'cpu'或'cuda'\n",
    "        \"\"\"\n",
    "        self.max_smiles = max_smiles\n",
    "        self.encoding_method = encoding_method\n",
    "        self.fingerprint_size = fingerprint_size\n",
    "        self.radius = radius\n",
    "        self.use_features = use_features\n",
    "        self.device = device\n",
    "        self.descriptor_names = self._get_descriptor_names()\n",
    "        self.single_smiles_feature_size = self._get_single_feature_size()\n",
    "        self.feature_size = self.single_smiles_feature_size * max_smiles + 1  # +1 for concentration\n",
    "        print(f\"已初始化多SMILES編碼器: 方法={encoding_method}, 最大SMILES數={max_smiles}\")\n",
    "        print(f\"單個SMILES特徵維度={self.single_smiles_feature_size}, 總特徵維度={self.feature_size}\")\n",
    "    \n",
    "    def _get_descriptor_names(self):\n",
    "        \"\"\"取得RDKit分子描述符的名稱列表\"\"\"\n",
    "        descriptors = [\n",
    "            # 基本物理化學特性\n",
    "            'MolWt', 'HeavyAtomMolWt', 'ExactMolWt', 'NumValenceElectrons',\n",
    "            'FractionCSP3', 'NumRotatableBonds', 'NumHAcceptors', 'NumHDonors',\n",
    "            'NumHeteroatoms', 'NumAmideBonds', 'NumRings', 'NumAromaticRings',\n",
    "            'NumSaturatedRings', 'NumAliphaticRings', 'NumAromaticHeterocycles',\n",
    "            'NumSaturatedHeterocycles', 'NumAliphaticHeterocycles',\n",
    "            # LogP相關\n",
    "            'MolLogP', 'MolMR',\n",
    "            # 拓撲特性\n",
    "            'BalabanJ', 'BertzCT', 'Chi0', 'Chi1',\n",
    "            # 表面特性\n",
    "            'LabuteASA', 'TPSA'\n",
    "        ]\n",
    "        return descriptors\n",
    "    \n",
    "    def _get_single_feature_size(self):\n",
    "        \"\"\"計算單個SMILES特徵向量的長度\"\"\"\n",
    "        if self.encoding_method == 'morgan':\n",
    "            return self.fingerprint_size\n",
    "        elif self.encoding_method == 'descriptors':\n",
    "            return len(self.descriptor_names)\n",
    "        elif self.encoding_method == 'combined':\n",
    "            return self.fingerprint_size + len(self.descriptor_names)\n",
    "        else:\n",
    "            raise ValueError(f\"不支援的編碼方法: {self.encoding_method}\")\n",
    "    \n",
    "    def _get_morgan_fingerprint(self, mol):\n",
    "        \"\"\"計算分子的Morgan指紋\"\"\"\n",
    "        if not mol:\n",
    "            return np.zeros(self.fingerprint_size)\n",
    "        if self.use_features:\n",
    "            fp = AllChem.GetMorganFeaturesFingerprint(mol, self.radius)\n",
    "        else:\n",
    "            fp = AllChem.GetMorganFingerprint(mol, self.radius)\n",
    "        fp_array = np.zeros(self.fingerprint_size)\n",
    "        for idx, val in fp.GetNonzeroElements().items():\n",
    "            idx_in_array = idx % self.fingerprint_size\n",
    "            fp_array[idx_in_array] += val\n",
    "        return fp_array\n",
    "    \n",
    "    def _get_descriptors(self, mol):\n",
    "        \"\"\"計算分子的RDKit描述符\"\"\"\n",
    "        if not mol:\n",
    "            return np.zeros(len(self.descriptor_names))\n",
    "        \n",
    "        desc_values = []\n",
    "        for desc_name in self.descriptor_names:\n",
    "            try:\n",
    "                desc_func = getattr(Descriptors, desc_name)\n",
    "                value = desc_func(mol)\n",
    "            except:\n",
    "                # 若遇到錯誤，設為0\n",
    "                value = 0\n",
    "            desc_values.append(value)\n",
    "        \n",
    "        return np.array(desc_values)\n",
    "    \n",
    "    def encode_smiles(self, smiles):\n",
    "        \"\"\"\n",
    "        將單個SMILES字串編碼為數值向量。\n",
    "        \n",
    "        參數:\n",
    "            smiles (str): 要編碼的SMILES字串\n",
    "            \n",
    "        返回:\n",
    "            numpy.ndarray: 編碼後的特徵向量\n",
    "        \"\"\"\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if not mol:\n",
    "                print(f\"警告: 無法解析SMILES字串: {smiles}\")\n",
    "                return np.zeros(self.single_smiles_feature_size)\n",
    "            \n",
    "            if self.encoding_method == 'morgan':\n",
    "                return self._get_morgan_fingerprint(mol)\n",
    "            elif self.encoding_method == 'descriptors':\n",
    "                return self._get_descriptors(mol)\n",
    "            elif self.encoding_method == 'combined':\n",
    "                morgan_fp = self._get_morgan_fingerprint(mol)\n",
    "                descriptors = self._get_descriptors(mol)\n",
    "                return np.concatenate([morgan_fp, descriptors])\n",
    "        except Exception as e:\n",
    "            print(f\"處理SMILES時出錯 ({smiles}): {e}\")\n",
    "            return np.zeros(self.single_smiles_feature_size)\n",
    "    \n",
    "    def encode_multiple_smiles(self, smiles_list, concentrations):\n",
    "        \"\"\"\n",
    "        將多個SMILES字串及其對應濃度編碼為單一特徵向量。\n",
    "        \n",
    "        參數:\n",
    "            smiles_list (list): 要編碼的SMILES字串列表\n",
    "            concentrations (list): 對應的濃度列表\
